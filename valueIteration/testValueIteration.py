import sys
sys.path.append('../src/')

import numpy as np
import unittest
from ddt import ddt, data, unpack
import ValueIterationSolution as targetCode #change to file name


@ddt
class TestValueIteration(unittest.TestCase):
	def setUp(self): 
		# for the deterministic transition, goal state is (1,1), trap state is (1,2). The board is 3 (0,1,2) by 5 (0,1,2,3,4)
		# All states the same number of moves away from (1,1) that avoid traveling through the trap state will have the same value
		deterministicTransitionTable = {(0, 0): {(1, 0): {(1, 0): 1},(0, 1): {(0, 1): 1},(-1, 0): {(0, 0): 1},(0, -1): {(0, 0): 1},(0, 0): {(0, 0): 1}},(0, 1): {(1, 0): {(1, 1): 1},(0, 1): {(0, 2): 1},(-1, 0): {(0, 1): 1},(0, -1): {(0, 0): 1},(0, 0): {(0, 1): 1}},(0, 2): {(1, 0): {(1, 2): 1},(0, 1): {(0, 3): 1},(-1, 0): {(0, 2): 1},(0, -1): {(0, 1): 1},(0, 0): {(0, 2): 1}},(0, 3): {(1, 0): {(1, 3): 1},(0, 1): {(0, 4): 1},(-1, 0): {(0, 3): 1},(0, -1): {(0, 2): 1},(0, 0): {(0, 3): 1}},(0, 4): {(1, 0): {(1, 4): 1},(0, 1): {(0, 4): 1},(-1, 0): {(0, 4): 1},(0, -1): {(0, 3): 1},(0, 0): {(0, 4): 1}},(1, 0): {(1, 0): {(2, 0): 1},(0, 1): {(1, 1): 1},(-1, 0): {(0, 0): 1},(0, -1): {(1, 0): 1},(0, 0): {(1, 0): 1}},(1, 1): {(1, 0): {(2, 1): 1},(0, 1): {(1, 2): 1},(-1, 0): {(0, 1): 1},(0, -1): {(1, 0): 1},(0, 0): {(1, 1): 1}},(1, 2): {(1, 0): {(2, 2): 1},(0, 1): {(1, 3): 1},(-1, 0): {(0, 2): 1},(0, -1): {(1, 1): 1},(0, 0): {(1, 2): 1}},(1, 3): {(1, 0): {(2, 3): 1},(0, 1): {(1, 4): 1},(-1, 0): {(0, 3): 1},(0, -1): {(1, 2): 1},(0, 0): {(1, 3): 1}},(1, 4): {(1, 0): {(2, 4): 1},(0, 1): {(1, 4): 1},(-1, 0): {(0, 4): 1},(0, -1): {(1, 3): 1},(0, 0): {(1, 4): 1}},(2, 0): {(1, 0): {(2, 0): 1},(0, 1): {(2, 1): 1},(-1, 0): {(1, 0): 1},(0, -1): {(2, 0): 1},(0, 0): {(2, 0): 1}},(2, 1): {(1, 0): {(2, 1): 1},(0, 1): {(2, 2): 1},(-1, 0): {(1, 1): 1},(0, -1): {(2, 0): 1},(0, 0): {(2, 1): 1}},(2, 2): {(1, 0): {(2, 2): 1},(0, 1): {(2, 3): 1},(-1, 0): {(1, 2): 1},(0, -1): {(2, 1): 1},(0, 0): {(2, 2): 1}},(2, 3): {(1, 0): {(2, 3): 1},(0, 1): {(2, 4): 1},(-1, 0): {(1, 3): 1},(0, -1): {(2, 2): 1},(0, 0): {(2, 3): 1}},(2, 4): {(1, 0): {(2, 4): 1},(0, 1): {(2, 4): 1},(-1, 0): {(1, 4): 1},(0, -1): {(2, 3): 1},(0, 0): {(2, 4): 1}}}
		deterministicRewardTable = {(0, 0): {(1, 0): {(1, 0): -1},(0, 1): {(0, 1): -1},(-1, 0): {(0, 0): -1},(0, -1): {(0, 0): -1},(0, 0): {(0, 0): -0.1}},(0, 1): {(1, 0): {(1, 1): -1},(0, 1): {(0, 2): -1},(-1, 0): {(0, 1): -1},(0, -1): {(0, 0): -1},(0, 0): {(0, 1): -0.1}},(0, 2): {(1, 0): {(1, 2): -1},(0, 1): {(0, 3): -1},(-1, 0): {(0, 2): -1},(0, -1): {(0, 1): -1},(0, 0): {(0, 2): -0.1}},(0, 3): {(1, 0): {(1, 3): -1},(0, 1): {(0, 4): -1},(-1, 0): {(0, 3): -1},(0, -1): {(0, 2): -1},(0, 0): {(0, 3): -0.1}},(0, 4): {(1, 0): {(1, 4): -1},(0, 1): {(0, 4): -1},(-1, 0): {(0, 4): -1},(0, -1): {(0, 3): -1},(0, 0): {(0, 4): -0.1}},(1, 0): {(1, 0): {(2, 0): -1},(0, 1): {(1, 1): -1},(-1, 0): {(0, 0): -1},(0, -1): {(1, 0): -1},(0, 0): {(1, 0): -0.1}},(1, 1): {(1, 0): {(2, 1): 9},(0, 1): {(1, 2): 9},(-1, 0): {(0, 1): 9},(0, -1): {(1, 0): 9},(0, 0): {(1, 1): 9.9}},(1, 2): {(1, 0): {(2, 2): -100},(0, 1): {(1, 3): -100},(-1, 0): {(0, 2): -100},(0, -1): {(1, 1): -100},(0, 0): {(1, 2): -100}},(1, 3): {(1, 0): {(2, 3): -1},(0, 1): {(1, 4): -1},(-1, 0): {(0, 3): -1},(0, -1): {(1, 2): -1},(0, 0): {(1, 3): -0.1}},(1, 4): {(1, 0): {(2, 4): -1},(0, 1): {(1, 4): -1},(-1, 0): {(0, 4): -1},(0, -1): {(1, 3): -1},(0, 0): {(1, 4): -0.1}},(2, 0): {(1, 0): {(2, 0): -1},(0, 1): {(2, 1): -1},(-1, 0): {(1, 0): -1},(0, -1): {(2, 0): -1},(0, 0): {(2, 0): -0.1}},(2, 1): {(1, 0): {(2, 1): -1},(0, 1): {(2, 2): -1},(-1, 0): {(1, 1): -1},(0, -1): {(2, 0): -1},(0, 0): {(2, 1): -0.1}},(2, 2): {(1, 0): {(2, 2): -1},(0, 1): {(2, 3): -1},(-1, 0): {(1, 2): -1},(0, -1): {(2, 1): -1},(0, 0): {(2, 2): -0.1}},(2, 3): {(1, 0): {(2, 3): -1},(0, 1): {(2, 4): -1},(-1, 0): {(1, 3): -1},(0, -1): {(2, 2): -1},(0, 0): {(2, 3): -0.1}},(2, 4): {(1, 0): {(2, 4): -1},(0, 1): {(2, 4): -1},(-1, 0): {(1, 4): -1},(0, -1): {(2, 3): -1},(0, 0): {(2, 4): -0.1}}}
		determinsitcValueTable = {state:0 for state in deterministicRewardTable.keys()}

		# For the slippery transition, the goal state is (3,1), trap state is (1,1). The board is 4 by 4
		# Visualizations of the exact slip directions sampled for this transition can be found in the accompanying demo ipynb
		slipperyTransitionTable = {(0,0): {(1, 0): {(1, 0): 0.7,(0, 1): 0.20000000000000004,(0, 0): 0.10000000000000002}, (0, 1): {(0, 1): 0.7999999999999999,(1, 0): 0.20000000000000004}, (-1, 0): {(0, 0): 0.7,(1, 0): 0.20000000000000004,(0, 1): 0.10000000000000002}, (0, -1): {(0, 0): 0.7,(1, 0): 0.10000000000000002,(0, 1): 0.20000000000000004}, (0, 0): {(0, 0): 0.7999999999999999,(0, 1): 0.10000000000000002,(1, 0): 0.10000000000000002}},(0,1): {(1, 0): {(1, 1): 0.7,(0, 0): 0.10000000000000002,(0, 2): 0.10000000000000002,(0, 1): 0.10000000000000002}, (0, 1): {(0, 2): 0.7,(0, 1): 0.10000000000000002,(0, 0): 0.20000000000000004}, (-1, 0): {(0, 1): 0.7999999999999999,(0, 2): 0.10000000000000002,(0, 0): 0.10000000000000002}, (0, -1): {(0, 0): 0.8999999999999999,(0, 1): 0.10000000000000002}, (0, 0): {(0, 1): 0.7999999999999999,(0, 2): 0.10000000000000002,(0, 0): 0.10000000000000002}},(0, 2): {(1, 0): {(1, 2): 0.7999999999999999, (0, 3): 0.20000000000000004},(0, 1): {(0, 3): 0.7, (0, 1): 0.30000000000000004},(-1, 0): {(0, 2): 0.7,(0, 3): 0.20000000000000004,(1, 2): 0.10000000000000002},(0, -1): {(0, 1): 0.7,(0, 2): 0.20000000000000004,(1, 2): 0.10000000000000002},(0, 0): {(0, 2): 0.7,(1, 2): 0.20000000000000004,(0, 1): 0.10000000000000002}},(0,3): {(1, 0): {(1, 3): 0.7999999999999999,(0, 2): 0.10000000000000002,(0, 3): 0.10000000000000002}, (0, 1): {(0, 3): 0.9999999999999999}, (-1,0): {(0, 3): 0.7999999999999999,(1, 3): 0.10000000000000002,(0, 2): 0.10000000000000002}, (0, -1): {(0, 2): 0.7999999999999999,(1, 3): 0.20000000000000004}, (0, 0): {(0, 3): 0.7,(0, 2): 0.10000000000000002,(1, 3): 0.20000000000000004}},(1,0): {(1, 0): {(2, 0): 0.7,(0, 0): 0.10000000000000002,(1, 0): 0.10000000000000002,(1, 1): 0.10000000000000002}, (0, 1): {(1, 1): 0.7999999999999999,(2, 0): 0.10000000000000002,(1, 0): 0.10000000000000002}, (-1, 0): {(0, 0): 0.7,(1, 1): 0.10000000000000002,(2, 0): 0.20000000000000004}, (0, -1): {(1, 0): 0.7999999999999999,(0, 0): 0.20000000000000004}, (0, 0): {(1, 0): 0.7999999999999999,(1, 1): 0.10000000000000002,(0, 0): 0.10000000000000002}},(1, 1): {(1, 0): {(2, 1): 0.8999999999999999, (1, 0): 0.10000000000000002},(0, 1): {(1, 2): 0.7999999999999999,(1, 0): 0.10000000000000002,(1, 1): 0.10000000000000002},(-1, 0): {(0, 1): 0.8999999999999999, (1, 2): 0.10000000000000002},(0, -1): {(1, 0): 0.7,(0, 1): 0.10000000000000002,(1, 2): 0.20000000000000004},(0, 0): {(1, 1): 0.7,(1, 2): 0.10000000000000002,(2, 1): 0.10000000000000002,(1, 0): 0.10000000000000002}},(1,2): {(1, 0): {(2, 2): 0.7999999999999999,(1, 3): 0.10000000000000002,(0, 2): 0.10000000000000002}, (0, 1): {(1, 3): 0.8999999999999999,(0, 2): 0.10000000000000002}, (-1, 0): {(0, 2): 0.7,(1, 2): 0.10000000000000002,(2, 2): 0.10000000000000002,(1, 3): 0.10000000000000002}, (0, -1): {(1, 1): 0.7999999999999999,(2, 2): 0.20000000000000004}, (0, 0): {(1, 2): 0.7,(2, 2): 0.20000000000000004,(1, 1): 0.10000000000000002}},(1,3): {(1, 0): {(2, 3): 0.7,(0, 3): 0.20000000000000004,(1, 2): 0.10000000000000002}, (0, 1): {(1, 3): 0.7,(2, 3): 0.20000000000000004,(0, 3): 0.10000000000000002}, (-1, 0): {(0, 3): 0.8999999999999999,(2, 3): 0.10000000000000002}, (0, -1): {(1, 2): 0.8999999999999999,(1, 3): 0.10000000000000002}, (0, 0): {(1, 3): 0.7999999999999999,(0, 3): 0.10000000000000002,(1, 2): 0.10000000000000002}},(2,0): {(1, 0): {(3, 0): 0.7,(2, 0): 0.20000000000000004,(1, 0): 0.10000000000000002}, (0, 1): {(2, 1): 0.7,(2, 0): 0.20000000000000004,(1, 0): 0.10000000000000002}, (-1, 0): {(1, 0): 0.7,(2, 0): 0.20000000000000004,(3, 0): 0.10000000000000002}, (0, -1): {(2, 0): 0.7999999999999999,(2, 1): 0.10000000000000002,(3, 0): 0.10000000000000002}, (0, 0): {(2, 0): 0.7,(3, 0): 0.10000000000000002,(1, 0): 0.20000000000000004}},(2,1): {(1, 0): {(3, 1): 0.7999999999999999,(2, 1): 0.10000000000000002,(1, 1): 0.10000000000000002}, (0, 1): {(2, 2): 0.7999999999999999,(2, 0): 0.10000000000000002,(3, 1): 0.10000000000000002}, (-1, 0): {(1, 1): 0.7,(2, 2): 0.20000000000000004,(3, 1): 0.10000000000000002}, (0, -1): {(2, 0): 0.7,(3, 1): 0.10000000000000002,(1, 1): 0.10000000000000002,(2, 2): 0.10000000000000002}, (0, 0): {(2, 1): 0.7,(2, 2): 0.30000000000000004}},(2,2): {(1, 0): {(3, 2): 0.7,(2, 2): 0.20000000000000004,(2, 1): 0.10000000000000002}, (0, 1): {(2, 3): 0.7999999999999999,(2, 2): 0.20000000000000004}, (-1, 0): {(1, 2): 0.7,(2, 1): 0.10000000000000002,(2, 2): 0.10000000000000002,(3, 2): 0.10000000000000002}, (0, -1): {(2, 1): 0.7999999999999999,(2, 2): 0.10000000000000002,(2, 3): 0.10000000000000002}, (0, 0): {(2, 2): 0.7999999999999999,(3, 2): 0.10000000000000002,(1, 2): 0.10000000000000002}},(2,3): {(1, 0): {(3, 3): 0.7,(1, 3): 0.20000000000000004,(2, 2): 0.10000000000000002}, (0, 1): {(2, 3): 0.7999999999999999,(1, 3): 0.10000000000000002,(3, 3): 0.10000000000000002}, (-1, 0): {(1, 3): 0.7999999999999999,(2, 3): 0.10000000000000002,(2, 2): 0.10000000000000002}, (0, -1): {(2, 2): 0.7,(3, 3): 0.10000000000000002,(1, 3): 0.10000000000000002,(2, 3): 0.10000000000000002}, (0, 0): {(2, 3): 0.8999999999999999,(3, 3): 0.10000000000000002}},(3,0): {(1, 0): {(3, 0): 0.7999999999999999,(3, 1): 0.10000000000000002,(2, 0): 0.10000000000000002}, (0, 1): {(3, 1): 0.7999999999999999,(3, 0): 0.20000000000000004}, (-1, 0): {(2, 0): 0.7999999999999999,(3, 1): 0.20000000000000004}, (0, -1): {(3, 0): 0.8999999999999999,(3, 1): 0.10000000000000002}, (0, 0): {(3, 0): 0.7999999999999999,(3, 1): 0.10000000000000002,(2, 0): 0.10000000000000002}},(3,1): {(1, 0): {(3, 1): 0.7,(3, 2): 0.20000000000000004,(2, 1): 0.10000000000000002}, (0, 1): {(3, 2): 0.8999999999999999,(3, 0): 0.10000000000000002}, (-1, 0): {(2, 1): 0.7,(3, 1): 0.20000000000000004,(3, 0): 0.10000000000000002}, (0, -1): {(3, 0): 0.7999999999999999,(3, 1): 0.10000000000000002,(2, 1): 0.10000000000000002}, (0, 0): {(3, 1): 0.7999999999999999,(3, 0): 0.10000000000000002,(3, 2): 0.10000000000000002}},(3,2): {(1, 0): {(3, 2): 0.7999999999999999,(3, 1): 0.10000000000000002,(2, 2): 0.10000000000000002}, (0, 1): {(3, 3): 0.7999999999999999,(3, 1): 0.20000000000000004}, (-1, 0): {(2, 2): 0.7,(3, 2): 0.10000000000000002,(3, 3): 0.10000000000000002,(3, 1): 0.10000000000000002}, (0, -1): {(3, 1): 0.7999999999999999,(2, 2): 0.10000000000000002,(3, 3): 0.10000000000000002}, (0, 0): {(3, 2): 0.7,(3, 3): 0.20000000000000004,(3, 1): 0.10000000000000002}},(3, 3): {(1, 0): {(3, 3): 0.7, (2, 3): 0.30000000000000004},(0, 1): {(3, 3): 0.7,(3, 2): 0.10000000000000002,(2, 3): 0.20000000000000004},(-1, 0): {(2, 3): 0.7999999999999999,(3, 2): 0.10000000000000002,(3, 3): 0.10000000000000002},(0, -1): {(3, 2): 0.8999999999999999, (3, 3): 0.10000000000000002},(0, 0): {(3, 3): 0.7999999999999999, (3, 2): 0.20000000000000004}}}
		slipperyRewardTable = {(0, 0): {(1, 0): {(1, 0): -1, (0, 1): -1, (0, 0): -1},(0, 1): {(0, 1): -1, (1, 0): -1},(-1, 0): {(0, 0): -1, (1, 0): -1, (0, 1): -1},(0, -1): {(0, 0): -1, (1, 0): -1, (0, 1): -1},(0, 0): {(0, 0): -0.1, (0, 1): -0.1, (1, 0): -0.1}},(0, 1): {(1, 0): {(1, 1): -1, (0, 0): -1, (0, 2): -1, (0, 1): -1},(0, 1): {(0, 2): -1, (0, 1): -1, (0, 0): -1},(-1, 0): {(0, 1): -1, (0, 2): -1, (0, 0): -1},(0, -1): {(0, 0): -1, (0, 1): -1},(0, 0): {(0, 1): -0.1, (0, 2): -0.1, (0, 0): -0.1}},(0, 2): {(1, 0): {(1, 2): -1, (0, 3): -1},(0, 1): {(0, 3): -1, (0, 1): -1},(-1, 0): {(0, 2): -1, (0, 3): -1, (1, 2): -1},(0, -1): {(0, 1): -1, (0, 2): -1, (1, 2): -1},(0, 0): {(0, 2): -0.1, (1, 2): -0.1, (0, 1): -0.1}},(0, 3): {(1, 0): {(1, 3): -1, (0, 2): -1, (0, 3): -1},(0, 1): {(0, 3): -1},(-1, 0): {(0, 3): -1, (1, 3): -1, (0, 2): -1},(0, -1): {(0, 2): -1, (1, 3): -1},(0, 0): {(0, 3): -0.1, (0, 2): -0.1, (1, 3): -0.1}},(1, 0): {(1, 0): {(2, 0): -1, (0, 0): -1, (1, 0): -1, (1, 1): -1},(0, 1): {(1, 1): -1, (2, 0): -1, (1, 0): -1},(-1, 0): {(0, 0): -1, (1, 1): -1, (2, 0): -1},(0, -1): {(1, 0): -1, (0, 0): -1},(0, 0): {(1, 0): -0.1, (1, 1): -0.1, (0, 0): -0.1}},(1, 1): {(1, 0): {(2, 1): -100, (1, 0): -100},(0, 1): {(1, 2): -100, (1, 0): -100, (1, 1): -100},(-1, 0): {(0, 1): -100, (1, 2): -100},(0, -1): {(1, 0): -100, (0, 1): -100, (1, 2): -100},(0, 0): {(1, 1): -100, (1, 2): -100, (2, 1): -100, (1, 0): -100}},(1, 2): {(1, 0): {(2, 2): -1, (1, 3): -1, (0, 2): -1},(0, 1): {(1, 3): -1, (0, 2): -1},(-1, 0): {(0, 2): -1, (1, 2): -1, (2, 2): -1, (1, 3): -1},(0, -1): {(1, 1): -1, (2, 2): -1},(0, 0): {(1, 2): -0.1, (2, 2): -0.1, (1, 1): -0.1}},(1, 3): {(1, 0): {(2, 3): -1, (0, 3): -1, (1, 2): -1},(0, 1): {(1, 3): -1, (2, 3): -1, (0, 3): -1},(-1, 0): {(0, 3): -1, (2, 3): -1},(0, -1): {(1, 2): -1, (1, 3): -1},(0, 0): {(1, 3): -0.1, (0, 3): -0.1, (1, 2): -0.1}},(2, 0): {(1, 0): {(3, 0): -1, (2, 0): -1, (1, 0): -1},(0, 1): {(2, 1): -1, (2, 0): -1, (1, 0): -1},(-1, 0): {(1, 0): -1, (2, 0): -1, (3, 0): -1},(0, -1): {(2, 0): -1, (2, 1): -1, (3, 0): -1},(0, 0): {(2, 0): -0.1, (3, 0): -0.1, (1, 0): -0.1}},(2, 1): {(1, 0): {(3, 1): -1, (2, 1): -1, (1, 1): -1},(0, 1): {(2, 2): -1, (2, 0): -1, (3, 1): -1},(-1, 0): {(1, 1): -1, (2, 2): -1, (3, 1): -1},(0, -1): {(2, 0): -1, (3, 1): -1, (1, 1): -1, (2, 2): -1},(0, 0): {(2, 1): -0.1, (2, 2): -0.1}},(2, 2): {(1, 0): {(3, 2): -1, (2, 2): -1, (2, 1): -1},(0, 1): {(2, 3): -1, (2, 2): -1},(-1, 0): {(1, 2): -1, (2, 1): -1, (2, 2): -1, (3, 2): -1},(0, -1): {(2, 1): -1, (2, 2): -1, (2, 3): -1},(0, 0): {(2, 2): -0.1, (3, 2): -0.1, (1, 2): -0.1}},(2, 3): {(1, 0): {(3, 3): -1, (1, 3): -1, (2, 2): -1},(0, 1): {(2, 3): -1, (1, 3): -1, (3, 3): -1},(-1, 0): {(1, 3): -1, (2, 3): -1, (2, 2): -1},(0, -1): {(2, 2): -1, (3, 3): -1, (1, 3): -1, (2, 3): -1},(0, 0): {(2, 3): -0.1, (3, 3): -0.1}},(3, 0): {(1, 0): {(3, 0): -1, (3, 1): -1, (2, 0): -1},(0, 1): {(3, 1): -1, (3, 0): -1},(-1, 0): {(2, 0): -1, (3, 1): -1},(0, -1): {(3, 0): -1, (3, 1): -1},(0, 0): {(3, 0): -0.1, (3, 1): -0.1, (2, 0): -0.1}},(3, 1): {(1, 0): {(3, 1): 9, (3, 2): 9, (2, 1): 9},(0, 1): {(3, 2): 9, (3, 0): 9},(-1, 0): {(2, 1): 9, (3, 1): 9, (3, 0): 9},(0, -1): {(3, 0): 9, (3, 1): 9, (2, 1): 9},(0, 0): {(3, 1): 9.9, (3, 0): 9.9, (3, 2): 9.9}},(3, 2): {(1, 0): {(3, 2): -1, (3, 1): -1, (2, 2): -1},(0, 1): {(3, 3): -1, (3, 1): -1},(-1, 0): {(2, 2): -1, (3, 2): -1, (3, 3): -1, (3, 1): -1},(0, -1): {(3, 1): -1, (2, 2): -1, (3, 3): -1},(0, 0): {(3, 2): -0.1, (3, 3): -0.1, (3, 1): -0.1}},(3, 3): {(1, 0): {(3, 3): -1, (2, 3): -1},(0, 1): {(3, 3): -1, (3, 2): -1, (2, 3): -1},(-1, 0): {(2, 3): -1, (3, 2): -1, (3, 3): -1},(0, -1): {(3, 2): -1, (3, 3): -1},(0, 0): {(3, 3): -0.1, (3, 2): -0.1}}}
		slipperyValueTable = {state:0 for state in slipperyRewardTable.keys()}

		convergenceTolerance = .000001
		gamma = .9

		self.performDeterministicTransitionValueIteration = targetCode.ValueIteration(deterministicTransitionTable, deterministicRewardTable, determinsitcValueTable, convergenceTolerance, gamma)
		self.performSlipperyTransitionValueIteration = targetCode.ValueIteration(slipperyTransitionTable, slipperyRewardTable, slipperyValueTable, convergenceTolerance, gamma)
	

	@data(((1,1), (1,2)), ((1,1), (1,0)), ((1,3), (1,4))) 
	@unpack
	def test_relativeStateValues_DeterministicTransition_FirstStateGreaterValue(self, state1, state2, roundingTolerance = 5):
		optimalValues, _ = self.performDeterministicTransitionValueIteration()
		
		state1Value = round(optimalValues[state1], roundingTolerance)
		state2Value = round(optimalValues[state2], roundingTolerance)

		calculatedRelativeStateValueSign = np.sign(state1Value - state2Value)
		expectedSign = 1
		self.assertEqual(calculatedRelativeStateValueSign, expectedSign)


	@data(((0,1), (2,1)), ((0,1), (1,0)), ((0,0), (2,0)), ((0,0), (2,2)), ((0,4), (1,3)))
	@unpack
	def test_relativeStateValues_DeterministicTransition_EquivalentValueStates(self, state1, state2, roundingTolerance = 5):
		optimalValues, _ = self.performDeterministicTransitionValueIteration()
		
		state1Value = round(optimalValues[state1], roundingTolerance)
		state2Value = round(optimalValues[state2], roundingTolerance)

		calculatedRelativeStateValueSign = np.sign(state1Value - state2Value)
		expectedSign = 0
		self.assertEqual(calculatedRelativeStateValueSign, expectedSign)


	@data(((3,1), (1,1)), ((2,1), (0,1)))
	@unpack
	def test_relativeStateValues_SlipperyTransition_FirstStateGreaterValue(self, state1, state2, roundingTolerance = 5):
		optimalValues, _ = self.performSlipperyTransitionValueIteration()
		
		state1Value = round(optimalValues[state1], roundingTolerance)
		state2Value = round(optimalValues[state2], roundingTolerance)

		calculatedRelativeStateValueSign = np.sign(state1Value - state2Value)
		expectedSign = 1
		self.assertEqual(calculatedRelativeStateValueSign, expectedSign)

	@data(((1,2), (1,0), 1), ((3,0), (3,2)))
	@unpack
	def test_relativeStateValues_SlipperyTransition_FirstStateGreaterValue_UsedToBeEquivalentForDeterministic(self, state1, state2, roundingTolerance = 5):
		optimalValues, _ = self.performSlipperyTransitionValueIteration()
		
		state1Value = round(optimalValues[state1], roundingTolerance)
		state2Value = round(optimalValues[state2], roundingTolerance)

		calculatedRelativeStateValueSign = np.sign(state1Value - state2Value)
		expectedSign = 1
		self.assertEqual(calculatedRelativeStateValueSign, expectedSign)

	@data(((0,1), (1,0)))
	@unpack
	def test_isActionNonzeroInProbability_NonzeroProb_DeterministicTransition_SingleOptimalDirection(self, state, action):
		_, policy = self.performDeterministicTransitionValueIteration()
		isActionNonZeroInProbability = action in policy[state].keys()
		self.assertTrue(isActionNonZeroInProbability)


	@data(((0,2), (1,0)), ((0,0), (-1,0)), ((0,1), (0,-1)), ((2,0), (0,0)))
	@unpack
	def test_isActionNonzeroInProbability_ZeroProb_DeterministicTransition_ToTrapState(self, state, action):
		_, policy = self.performDeterministicTransitionValueIteration()
		isActionNonZeroInProbability = action in policy[state].keys()
		self.assertFalse(isActionNonZeroInProbability)

	
	@data(((0,0), (-1,0)))
	@unpack
	def test_isActionNonzeroInProbability_ZeroProb_DeterministicTransition_OffBoard(self, state, action):
		_, policy = self.performDeterministicTransitionValueIteration()
		isActionNonZeroInProbability = action in policy[state].keys()
		self.assertFalse(isActionNonZeroInProbability)

	
	@data(((0,1), (0,-1)), ((2,0), (0,0)))
	@unpack
	def test_isActionNonzeroInProbability_ZeroProb_DeterministicTransition_SubOptimal(self, state, action):
		_, policy = self.performDeterministicTransitionValueIteration()
		isActionNonZeroInProbability = action in policy[state].keys()
		self.assertFalse(isActionNonZeroInProbability)



	# Not Vital to pass -- may be different if the implementation is different (didn't specify what to do when there are multiple optimal options)
	@data(((0,0), (1,0)), ((0,0), (0,1)), 
	((1,4), (1,0)), ((1,4), (0,-1)), ((1,4), (-1,0)))
	@unpack
	def test_nonVital_isActionNonzeroInProbability_NonzeroProb_DeterministicTransition_MultipleOptimalDirections(self, state, action):
		_, policy = self.performDeterministicTransitionValueIteration()
		isActionNonZeroInProbability = action in policy[state].keys()
		self.assertTrue(isActionNonZeroInProbability)

	#checks actual state values
	@data(((1, 2), -10.900008002471822), ((1, 1), 98.99999110836464), ((2, 1), 88.09999199752818))
	@unpack
	def test_nonVital_valueTableValues_DeterminsiticTransition(self, state, expectedResult):
		values, _ = self.performDeterministicTransitionValueIteration()
		stateValue = values[state]
		self.assertAlmostEqual(stateValue, expectedResult)


	#checks actual state values
	@data(((1, 1), -52.086043142042946), ((3, 1), 77.88220629640044), ((2, 1), 55.3708174669154))
	@unpack
	def test_nonVital_valueTableValues_SlipperyTransition(self, state, expectedResult):
		values, _ = self.performSlipperyTransitionValueIteration()
		stateValue = values[state]
		self.assertAlmostEqual(stateValue, expectedResult)

	def tearDown(self):
		pass
 
if __name__ == '__main__':
	unittest.main(verbosity=2)